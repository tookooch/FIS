{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1deDssg5VpJAqtxsROggq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVHClQ1T8eUN","executionInfo":{"status":"ok","timestamp":1738187603568,"user_tz":-210,"elapsed":9778,"user":{"displayName":"Mohaddeseh Feizi","userId":"04337067859358828796"}},"outputId":"7694adf9-bf11-43fd-cbe6-ad59f7f5f42e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.12.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.17.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2024.12.14)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading...\n","From: https://drive.google.com/uc?id=1sFzjheIoL6-JF7OKvF-ml6zLdyMBHlGr\n","To: /content/air+quality.zip\n","100% 1.54M/1.54M [00:00<00:00, 25.2MB/s]\n","Archive:  air+quality.zip\n","  inflating: AirQualityUCI.csv       \n","  inflating: AirQualityUCI.xlsx      \n"]}],"source":["!pip install --upgrade --no-cache-dir gdown\n","!gdown 1sFzjheIoL6-JF7OKvF-ml6zLdyMBHlGr\n","!unzip air+quality.zip"]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"NGjkLXTdB6q_","executionInfo":{"status":"ok","timestamp":1738187607952,"user_tz":-210,"elapsed":4387,"user":{"displayName":"Mohaddeseh Feizi","userId":"04337067859358828796"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('AirQualityUCI.csv')\n","\n","# اگر فایل شما Excel است، می‌توانید از این خط استفاده کنید:\n","# df = pd.read_excel('AirQualityUCI.xlsx')\n","\n","# ابتدا داده‌ها را به دو دسته train (80%) و temp (20%) تقسیم می‌کنیم\n","train_data, temp_data = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# سپس داده‌های temp را به دو بخش validation و test (هر کدام 50% از 20% داده‌ها) تقسیم می‌کنیم\n","validation_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n","\n","# حالا سه دسته داریم:\n","# train_data (60%)\n","# validation_data (20%)\n","# test_data (20%)\n","\n","# نمایش اندازه‌های دسته‌ها\n","print(f\"Train data size: {len(train_data)}\")\n","print(f\"Validation data size: {len(validation_data)}\")\n","print(f\"Test data size: {len(test_data)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Q7DLC1eCFYG","executionInfo":{"status":"ok","timestamp":1738187607953,"user_tz":-210,"elapsed":5,"user":{"displayName":"Mohaddeseh Feizi","userId":"04337067859358828796"}},"outputId":"a7842942-11c3-4ed8-92b3-20f59ad75c3c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Train data size: 7576\n","Validation data size: 947\n","Test data size: 948\n"]}]},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","from scipy.spatial.distance import cdist\n","import numpy as np\n","\n","class RBFNetwork:\n","    def __init__(self, num_centers):\n","        self.num_centers = num_centers  # تعداد مراکز (نودهای مخفی)\n","        self.centers = None  # مراکز توابع گوسی\n","        self.sigma = None  # مقدار سیگما برای گوسی‌ها\n","        self.weights = None  # وزن‌های لایه خروجی\n","\n","    def rbf_function(self, X, centers, sigma):\n","        \"\"\"محاسبه مقادیر گوسی برای ورودی X\"\"\"\n","        distances = cdist(X, centers)  # فاصله بین نمونه‌ها و مراکز\n","        return np.exp(- (distances ** 2) / (2 * sigma ** 2))\n","\n","    def fit(self, X_train, y_train):\n","        \"\"\"آموزش مدل با تنظیم مراکز، سیگما و وزن‌های خروجی\"\"\"\n","        # 1. انتخاب مراکز با K-Means\n","        kmeans = KMeans(n_clusters=self.num_centers, random_state=42, n_init=10)\n","        kmeans.fit(X_train)\n","        self.centers = kmeans.cluster_centers_\n","\n","        # 2. محاسبه سیگما (میانگین فاصله مراکز)\n","        d_max = np.max(cdist(self.centers, self.centers))  # بیشترین فاصله بین مراکز\n","        self.sigma = d_max / np.sqrt(2 * self.num_centers)  # مقداردهی اولیه سیگما\n","\n","        # 3. محاسبه خروجی توابع پایه (لایه مخفی)\n","        Phi = self.rbf_function(X_train, self.centers, self.sigma)\n","\n","        # 4. محاسبه وزن‌های خروجی با حداقل مربعات\n","        self.weights = np.linalg.pinv(Phi) @ y_train  # حل معادله خطی\n","\n","    def predict(self, X):\n","        \"\"\"پیش‌بینی خروجی مدل\"\"\"\n","        Phi = self.rbf_function(X, self.centers, self.sigma)\n","        return Phi @ self.weights  # ضرب مقدار توابع مخفی در وزن‌های خروجی\n","\n","# 2. اجرای RBF بر روی داده‌ها\n","num_centers = 10  # تعداد نودهای مخفی (قابل تنظیم)\n","rbf_net = RBFNetwork(num_centers=num_centers)\n","rbf_net.fit(X_train, y_train)\n","\n","# 3. پیش‌بینی بر روی داده‌های تست\n","y_pred_rbf = rbf_net.predict(X_test)\n","\n","# 4. محاسبه خطای مدل RBF\n","rbf_mse = np.mean((y_test - y_pred_rbf) ** 2)\n","print(f\"RBF Test MSE: {rbf_mse:.6f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tEO3wpBqKzwR","executionInfo":{"status":"ok","timestamp":1738189636337,"user_tz":-210,"elapsed":978,"user":{"displayName":"Mohaddeseh Feizi","userId":"04337067859358828796"}},"outputId":"9bb07c06-ddaf-4903-bd60-345106dcc7ac"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["RBF Test MSE: 0.063533\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# 1. بارگذاری و پیش‌پردازش داده‌ها\n","df = pd.read_csv('AirQualityUCI.csv', delimiter=';')\n","df = df.drop(columns=['Date', 'Time'])  # حذف ستون‌های غیرعددی\n","df = df.apply(pd.to_numeric, errors='coerce').fillna(0)  # تبدیل مقادیر نامعتبر و جایگزینی NaN با 0\n","\n","X = df.drop(columns=['CO(GT)']).values\n","y = df['CO(GT)'].values.reshape(-1, 1)\n","\n","# 2. تقسیم‌بندی داده‌ها به Train، Validation و Test\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","# 3. نرمال‌سازی داده‌ها\n","scaler_X = MinMaxScaler()\n","scaler_y = MinMaxScaler()\n","X_train = scaler_X.fit_transform(X_train)\n","X_val = scaler_X.transform(X_val)\n","X_test = scaler_X.transform(X_test)\n","y_train = scaler_y.fit_transform(y_train)\n","y_val = scaler_y.transform(y_val)\n","y_test = scaler_y.transform(y_test)\n","\n","# 4. تعریف تابع عضویت گوسی\n","def gaussmf(x, mean, sigma):\n","    return np.exp(-((x - mean) ** 2) / (2 * sigma ** 2))\n","\n","# 5. تنظیم پارامترهای اولیه ANFIS\n","num_features = X_train.shape[1]  # تعداد ویژگی‌ها\n","num_mfs = 2  # تعداد توابع عضویت برای هر ویژگی\n","num_rules = num_mfs ** num_features  # تعداد قواعد فازی\n","\n","# Ensure correct broadcasting of min/max values by expanding the shape\n","means = np.random.uniform(\n","    np.min(X_train, axis=0)[:, np.newaxis],  # Add a new axis to make shape (num_features, 1)\n","    np.max(X_train, axis=0)[:, np.newaxis],  # Add a new axis to make shape (num_features, 1)\n","    size=(num_features, num_mfs)  # Shape: (features, membership_functions)\n",")\n","\n","# Small initial sigma values, no changes needed\n","sigmas = np.random.uniform(0.1, 0.5, size=(num_features, num_mfs))\n","\n","# مقداردهی اولیه وزن‌های قوانین\n","rule_weights = np.random.rand(num_rules)\n","\n","def compute_membership(X, means, sigmas):\n","    membership = np.zeros((X.shape[0], num_features, num_mfs))\n","    for i in range(num_features):\n","        for j in range(num_mfs):\n","            mean, sigma = means[i, j], sigmas[i, j]\n","            membership[:, i, j] = gaussmf(X[:, i], mean, sigma)\n","    return membership\n","\n","def compute_rules_output(membership):\n","    rules_output = np.ones((membership.shape[0], num_rules))\n","    for rule_idx in range(num_rules):\n","        rule_input = np.unravel_index(rule_idx, (num_mfs,) * num_features)\n","        rule_memberships = np.ones(membership.shape[0])\n","        for feature_idx, mf_idx in enumerate(rule_input):\n","            rule_memberships *= membership[:, feature_idx, mf_idx]\n","        rules_output[:, rule_idx] = rule_memberships\n","    return rules_output\n","\n","# 6. آموزش مدل ANFIS\n","epochs = 50\n","learning_rate = 0.1\n","\n","# Initialization of rule_weights as a vector with the shape (num_rules,)\n","rule_weights = np.random.rand(num_rules)  # Shape: (num_rules,)\n","\n","for epoch in range(epochs):\n","    # Compute membership values for training data\n","    membership_train = compute_membership(X_train, means, sigmas)\n","\n","    # Compute the output of the fuzzy rules\n","    rules_output_train = compute_rules_output(membership_train)\n","\n","    # Ensure the correct shape for rules_output_train\n","    assert rules_output_train.shape == (X_train.shape[0], num_rules), f\"Shape mismatch: {rules_output_train.shape} vs {(X_train.shape[0], num_rules)}\"\n","\n","    # Compute rule outputs for the training data\n","    y_pred_train = np.dot(rules_output_train, rule_weights)  # Shape: (num_samples,)\n","    y_pred_train = y_pred_train.reshape(-1, 1)  # تبدیل به بردار ستونی\n","\n","    error = y_train - y_pred_train\n","\n","\n","    # Compute the gradient: (num_rules, 1) = (num_rules, num_samples) . (num_samples, 1)\n","    gradient = -2 * np.dot(rules_output_train.T, error) / X_train.shape[0]  # Gradient should have shape (num_rules, 1)\n","\n","    # Ensure the gradient has the correct shape\n","    assert gradient.shape == (num_rules, 1), f\"Gradient shape mismatch: {gradient.shape} vs {(num_rules, 1)}\"\n","\n","    # Flatten the gradient to shape (num_rules,)\n","    gradient = gradient.flatten()  # Now gradient has shape (num_rules,)\n","\n","    # Update the rule weights using gradient descent\n","    rule_weights -= learning_rate * gradient  # Now the shapes should match\n","\n","    # Compute MSE for debugging and tracking the progress\n","    mse = np.mean(error ** 2)\n","    if epoch % 10 == 0:\n","        print(f\"Epoch {epoch}/{epochs}, MSE: {mse}\")\n","\n","# 7. ارزیابی مدل روی تست‌داده‌ها\n","# Compute membership values for test data\n","membership_test = compute_membership(X_test, means, sigmas)\n","\n","# Compute the output of the fuzzy rules for test data\n","rules_output_test = compute_rules_output(membership_test)\n","\n","# Predict the test output\n","y_pred_test = np.dot(rules_output_test, rule_weights)\n","\n","# Calculate test MSE\n","test_error = y_test - y_pred_test\n","test_mse = np.mean(test_error**2)\n","print(f\"Test MSE: {test_mse}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0prjNyt3-J-N","executionInfo":{"status":"ok","timestamp":1738189395701,"user_tz":-210,"elapsed":5909,"user":{"displayName":"Mohaddeseh Feizi","userId":"04337067859358828796"}},"outputId":"10263d8d-0514-49ec-912d-59e69848caac"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/50, MSE: 0.6780831934492974\n","Epoch 10/50, MSE: 0.6780804610062371\n","Epoch 20/50, MSE: 0.6780777286958433\n","Epoch 30/50, MSE: 0.6780749965181092\n","Epoch 40/50, MSE: 0.6780722644730283\n","Test MSE: 0.6903428738695045\n"]}]}]}